{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random \n",
    "from sklearn import linear_model\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "userBook = defaultdict(set)\n",
    "bookUser = defaultdict(set)\n",
    "num = 0\n",
    "train = []\n",
    "vali = []\n",
    "\n",
    "for user,book,rat in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    if num < 190001:\n",
    "        bookCount[book] += 1\n",
    "        totalRead += 1\n",
    "        userBook[user].add(book)\n",
    "        bookUser[book].add(user)\n",
    "        train.append((user, book, rat))\n",
    "    else: vali.append((user, book, rat))\n",
    "    num += 1\n",
    "        \n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7169\n",
      "7169\n",
      "[(381, 'b25543219'), (319, 'b76915592'), (313, 'b21517939'), (273, 'b75885962'), (271, 'b55315814'), (267, 'b52453648'), (263, 'b02830492'), (249, 'b39244888'), (248, 'b25118404'), (235, 'b75743714')]\n"
     ]
    }
   ],
   "source": [
    "print(len(bookCount))\n",
    "print(len(mostPopular))\n",
    "print(mostPopular[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(vali)\n",
    "for i in range(size):\n",
    "    user = vali[i][0]\n",
    "    count = 0\n",
    "    while count < len(bookCount):\n",
    "        ind = random.randint(0,len(mostPopular)-1)\n",
    "        if mostPopular[ind][1] not in userBook[user]:\n",
    "            temp = (user, mostPopular[ind][1], -1)\n",
    "            vali.append(temp)\n",
    "            break;\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(thre):\n",
    "    topBooks = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        topBooks.add(i)\n",
    "        if count > totalRead/thre: break\n",
    "    count = 0\n",
    "    for user, book, rating in vali:\n",
    "        if book in topBooks and int(rating) >= 0: count += 1\n",
    "        if book not in topBooks and int(rating) < 0: count += 1\n",
    "    return (count/len(vali))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem1: when the threshold is 2, the accuracy is 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6482148214821483\n"
     ]
    }
   ],
   "source": [
    "print(getAccuracy(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem2: when the threshold is 1,79, the accuracy is 0.65, which is slightly higher than using 2 as the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6526652665266527\n"
     ]
    }
   ],
   "source": [
    "print(getAccuracy(1.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem3: Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    c1 = len(s1.intersection(s2))\n",
    "    c2 = len(s1.union(s2))\n",
    "    \n",
    "    return (c1/c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "simi = []\n",
    "for i in range(len(vali)):\n",
    "    user = vali[i][0]\n",
    "    book = vali[i][1]\n",
    "    rating = vali[i][2]\n",
    "    high = 0\n",
    "    for b in userBook[user]:\n",
    "        high = max(high, Jaccard(bookUser[b], bookUser[book]))\n",
    "    simi.append(high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(thre):\n",
    "    count = 0\n",
    "    #print(thre)\n",
    "    for i in range(len(vali)):\n",
    "        user = vali[i][0]\n",
    "        book = vali[i][1]\n",
    "        rating = vali[i][2]\n",
    "        if simi[i] > thre and int(rating) >= 0: count += 1\n",
    "        if simi[i] < thre and int(rating) < 0: count += 1\n",
    "    return (count/len(vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,30):\n",
    "#     print(getAccuracy(i*0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two models\n",
    "def getCombinedAccuracy(topBookThre, jaccardThre):\n",
    "    topBooks = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        topBooks.add(i)\n",
    "        if count > totalRead/topBookThre: break\n",
    "            \n",
    "    count = 0\n",
    "    for i in range(len(vali)):\n",
    "        user, book, rating = vali[i][0], vali[i][1], vali[i][2]\n",
    "        if simi[i] > jaccardThre and int(rating) >= 0:\n",
    "            count += 1\n",
    "        elif int(rating) < 0:\n",
    "            count += 1\n",
    "            \n",
    "    return (count / len(vali))\n",
    "\n",
    "def predict(topBooks, userBook, bookUser, user, book, jaccardThre=0.01):\n",
    "    high = 0\n",
    "    for b in userBook[user]:\n",
    "        high = max(high, Jaccard(bookUser[b], bookUser[book]))\n",
    "        \n",
    "    if book in topBooks and high > jaccardThre:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9601960196019602"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCombinedAccuracy(1.0, 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190001\n"
     ]
    }
   ],
   "source": [
    "print(totalRead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem5: (my Kaggle username is Manxue Li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.txt\", 'w')\n",
    "\n",
    "topBooks = set()\n",
    "topBookThre=1.75\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    topBooks.add(i)\n",
    "    if count > totalRead/topBookThre: break\n",
    "        \n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    if predict(topBooks, userBook, bookUser, u, b) == 1 :\n",
    "        predictions.write(u + '-' + b + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + b + \",0\\n\")\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Category prediction baseline: Just consider some of the most common words from each category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "catDict = {\n",
    "  \"children\": 0,\n",
    "  \"comics_graphic\": 1,\n",
    "  \"fantasy_paranormal\": 2,\n",
    "  \"mystery_thriller_crime\": 3,\n",
    "  \"young_adult\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"userID-reviewID,prediction\\n\")\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "  cat = catDict['fantasy_paranormal'] # If there's no evidence, just choose the most common category in the dataset\n",
    "  words = l['review_text'].lower()\n",
    "  if 'children' in words:\n",
    "    cat = catDict['children']\n",
    "  if 'comic' in words:\n",
    "    cat = catDict['comics_graphic']\n",
    "  if 'fantasy' in words:\n",
    "    cat = catDict['fantasy_paranormal']\n",
    "  if 'mystery' in words:\n",
    "    cat = catDict['mystery_thriller_crime']\n",
    "  if 'young' in words:\n",
    "    cat = catDict['young_adult']\n",
    "  predictions.write(l['user_id'] + '-' + l['review_id'] + \",\" + str(cat) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature vector\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    r = ''.join([c for c in l['review_text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(72087, 'the'), (43996, 'and'), (38613, 'a'), (36966, 'to'), (36113, 'i'), (31713, 'of'), (21711, 'is'), (20493, 'in'), (19948, 'it'), (19102, 'this')]\n"
     ]
    }
   ],
   "source": [
    "### Just take the most popular words...\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "print(counts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum, words, wordId):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review_text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem7: feature vector and label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "test_X = []\n",
    "test_y = []\n",
    "num = 0\n",
    "\n",
    "for l in readGz(\"train_Category.json.gz\"):\n",
    "    if num < 190000:\n",
    "        train_X.append(feature(l))\n",
    "        train_y.append(l['genreID'])\n",
    "    else:\n",
    "        test_X.append(feature(l))\n",
    "        test_y.append(l['genreID'])\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCat(counts, dictSize, c):\n",
    "    # get the top popular words\n",
    "    words = [x[1] for x in counts[:dictSize]]\n",
    "    wordId = {}\n",
    "    wordSet = set(words)\n",
    "    num = 0\n",
    "    for w in words:\n",
    "        wordId[w] = num\n",
    "        num += 1\n",
    "    \n",
    "    train_X = []\n",
    "    train_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "    num = 0\n",
    "\n",
    "    for l in readGz(\"train_Category.json.gz\"):\n",
    "        if num < 190000:\n",
    "            train_X.append(feature(l, words, wordId))\n",
    "            train_y.append(l['genreID'])\n",
    "        else:\n",
    "            test_X.append(feature(l, words, wordId))\n",
    "            test_y.append(l['genreID'])\n",
    "        num += 1\n",
    "        \n",
    "    # train the model and generate prediction  \n",
    "    mod = linear_model.LogisticRegression(C=c)\n",
    "    mod.fit(train_X, train_y)\n",
    "    pred = mod.predict(test_X)\n",
    "    return pred\n",
    "    \n",
    "# calculate accuracy\n",
    "def getAccuracy(pred):\n",
    "    count = 0\n",
    "    for i in range(len(test_X)):\n",
    "        if pred[i] == test_y[i]: count += 1\n",
    "    return (count/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pred = predictCat(counts, 1000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem7: this is the accuracy of the model, 0.6417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6417\n"
     ]
    }
   ],
   "source": [
    "print(getAccuracy(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pred2 = predictCat(counts, 2000, 10)\n",
    "pred3 = predictCat(counts, 2000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pred4 = predictCat(counts, 1000, 10)\n",
    "pred5 = predictCat(counts, 1000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pred6 = predictCat(counts, 1000, 100)\n",
    "pred7 = predictCat(counts, 1000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/clairlmx/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pred8 = predictCat(counts, 1500, 10)\n",
    "pred9 = predictCat(counts, 1500, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6417\n",
      "0.6416\n",
      "0.6407\n",
      "0.6416\n",
      "0.6407\n",
      "0.6402\n",
      "0.6376\n",
      "0.6416\n",
      "0.6407\n"
     ]
    }
   ],
   "source": [
    "# 1000, 1: 0.6417\n",
    "print(getAccuracy(pred))\n",
    "print(getAccuracy(pred2))\n",
    "print(getAccuracy(pred3))\n",
    "print(getAccuracy(pred4))\n",
    "print(getAccuracy(pred5))\n",
    "print(getAccuracy(pred6))\n",
    "print(getAccuracy(pred7))\n",
    "print(getAccuracy(pred8))\n",
    "print(getAccuracy(pred9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
